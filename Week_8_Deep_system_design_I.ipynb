{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt2p4neWYQi1"
      },
      "source": [
        "<H1 style=\"text-align: center\">EEEM066 - Fundamentals of Machine Learning</H1>\n",
        "<H1 style=\"text-align: center\">Week - 8: Deep system design (I)</H1>\n",
        "\n",
        "> Dr. Xiatian (Eddy) Zhu, Dr Syed Sameed Husain\n",
        "\n",
        "> xiatian.zhu@surrey.ac.uk, sameed.husain@surrey.ac.uk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAcRq_42YQi2"
      },
      "source": [
        "**Introduction**\n",
        "\n",
        "This lab is about the designing a Resnet based deep learning system for classification task.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "Happy Programming!⚡⚡"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awf9eiHywRmo"
      },
      "source": [
        "# Contents\n",
        "\n",
        "<!-- **Training an image classifier**\n",
        "We will do the following steps in order:\n",
        "\n",
        "1) Load and normalize the CIFAR10 training and test datasets using torchvision\n",
        "\n",
        "2) Define a Resnet architecture\n",
        "\n",
        "3) Define a loss function\n",
        "\n",
        "4) Train the network on the training data\n",
        "\n",
        "5) Test the network on the test data -->\n",
        "\n",
        "*   [Load and normalize CIFAR10](https://colab.research.google.com/drive/1aBEIdwhC_7TFlPpaAeWTRwbeTGjZT3V0#scrollTo=FlBp3a3PYQjB)\n",
        "*   [Design a Resnet System](https://colab.research.google.com/drive/1aBEIdwhC_7TFlPpaAeWTRwbeTGjZT3V0#scrollTo=GV5WisJhYQjC)\n",
        "*   [Define a Loss function and optimizer](https://colab.research.google.com/drive/1aBEIdwhC_7TFlPpaAeWTRwbeTGjZT3V0#scrollTo=zJ4E8YvkYQjD)\n",
        "*   [Train the network on the training data](https://colab.research.google.com/drive/1aBEIdwhC_7TFlPpaAeWTRwbeTGjZT3V0#scrollTo=4XFeKdU3YQjE)\n",
        "*   [Test the network on the test data](https://colab.research.google.com/drive/1aBEIdwhC_7TFlPpaAeWTRwbeTGjZT3V0#scrollTo=Ncv2PSfCYQjE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQCxMrH7YQjB"
      },
      "source": [
        "**Python libraries required**\n",
        "1. Numpy\n",
        "4. torch\n",
        "5. torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlBp3a3PYQjB"
      },
      "source": [
        "## Load and normalize CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PegHytlRYQjB",
        "outputId": "c82a6a03-3e3a-4b44-b502-db893bc8b4b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 50028118.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=16)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=16)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV5WisJhYQjC"
      },
      "source": [
        "## Design a Resnet System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2dUJYdofYQjD"
      },
      "outputs": [],
      "source": [
        "# 3x3 convolution\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                     stride=stride, padding=1, bias=False)\n",
        "\n",
        "# Residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TB1tnQoaYQjD"
      },
      "outputs": [],
      "source": [
        "# ResNet\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ4E8YvkYQjD"
      },
      "source": [
        "## Define a Loss function and optimizer\n",
        "\n",
        "Let’s use a Classification Cross-Entropy loss and SGD with momentum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ANzpXY11YQjE"
      },
      "outputs": [],
      "source": [
        "learning_rate=0.005\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# For updating learning rate\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XFeKdU3YQjE"
      },
      "source": [
        "## Train the network on the training data\n",
        "\n",
        "We simply have to loop over our data iterator, and feed the inputs to the network and optimize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW6d8DxbYQjE",
        "outputId": "1df22b05-07e8-4424-ee0b-630018091793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/391] Loss: 1.5512\n",
            "Epoch [1/10], Step [200/391] Loss: 1.4568\n",
            "Epoch [1/10], Step [300/391] Loss: 1.4272\n",
            "Epoch [2/10], Step [100/391] Loss: 1.1992\n",
            "Epoch [2/10], Step [200/391] Loss: 0.9688\n",
            "Epoch [2/10], Step [300/391] Loss: 1.0585\n",
            "Epoch [3/10], Step [100/391] Loss: 0.8400\n",
            "Epoch [3/10], Step [200/391] Loss: 0.7869\n",
            "Epoch [3/10], Step [300/391] Loss: 0.7109\n",
            "Epoch [4/10], Step [100/391] Loss: 0.7630\n",
            "Epoch [4/10], Step [200/391] Loss: 0.7258\n",
            "Epoch [4/10], Step [300/391] Loss: 0.6135\n",
            "Epoch [5/10], Step [100/391] Loss: 0.6413\n",
            "Epoch [5/10], Step [200/391] Loss: 0.6867\n",
            "Epoch [5/10], Step [300/391] Loss: 0.6019\n",
            "Epoch [6/10], Step [100/391] Loss: 0.3655\n",
            "Epoch [6/10], Step [200/391] Loss: 0.6073\n",
            "Epoch [6/10], Step [300/391] Loss: 0.5267\n",
            "Epoch [7/10], Step [100/391] Loss: 0.6164\n",
            "Epoch [7/10], Step [200/391] Loss: 0.4763\n",
            "Epoch [7/10], Step [300/391] Loss: 0.3668\n",
            "Epoch [8/10], Step [100/391] Loss: 0.3796\n",
            "Epoch [8/10], Step [200/391] Loss: 0.4443\n",
            "Epoch [8/10], Step [300/391] Loss: 0.6259\n",
            "Epoch [9/10], Step [100/391] Loss: 0.4690\n",
            "Epoch [9/10], Step [200/391] Loss: 0.6351\n",
            "Epoch [9/10], Step [300/391] Loss: 0.4412\n",
            "Epoch [10/10], Step [100/391] Loss: 0.3874\n",
            "Epoch [10/10], Step [200/391] Loss: 0.5036\n",
            "Epoch [10/10], Step [300/391] Loss: 0.3434\n"
          ]
        }
      ],
      "source": [
        "num_epochs=10\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Decay learning rate\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        curr_lr /= 3\n",
        "        update_lr(optimizer, curr_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncv2PSfCYQjE"
      },
      "source": [
        "## Test the network on the test data\n",
        "\n",
        "We have trained the network. But we need to check the network performance on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozz86hMRYQjF",
        "outputId": "31d22afd-4fd4-41d5-c753-964c68c4ad08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the test images: 82.6 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'resnet.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
